# ğŸš€ MNIST Handwritten Digit Classification

This project implements and compares two classic machine learning algorithmsâ€”**Logistic Regression** and **Support Vector Machine (SVM)**â€”to classify handwritten digits from the widely-used **MNIST** dataset.

The MNIST dataset contains 70,000 grayscale images of handwritten digits (0â€“9), each sized $28 \times 28$ pixels.

-----

## ğŸ“‚ Project Structure

The repository is organized for clarity and easy navigation:

```
MNIST-ML-Models/
â”‚ 
â”œâ”€ ml_project11.py        # Main Python script 
â”œâ”€ requirements.txt       # Python dependencies 
â”œâ”€ results/               # Generated plots (confusion matrix, sample predictions) 
â””â”€ notebooks/             # Optional exploratory notebooks (currently empty)
```

-----

## ğŸ“ Workflow

The `ml_project11.py` script executes a complete machine learning pipeline:

1.  **ğŸ“¥ Data Loading:** Fetch the MNIST dataset using `fetch_openml`.
2.  **âš™ï¸ Preprocessing:**
      * Scale pixel values to the range $[0, 1]$.
      * Split the dataset 80% for training and 20% for testing.
      * Standardize features using `StandardScaler` specifically for the SVM model.
3.  **ğŸ¤– Model Training:**
      * **Logistic Regression:** Trained on the full 56,000-sample training set.
      * **SVM (RBF kernel):** Trained on a smaller 10,000-sample subset for efficiency.
4.  **ğŸ“Š Evaluation:** Calculate accuracy scores for both models, generate a confusion matrix, and visualize sample predictions.

-----

## ğŸ› ï¸ Requirements

The required Python dependencies for this project are:

```bash
pip install pandas numpy scikit-learn matplotlib seaborn
```

-----

## ğŸ Getting Started

### Clone the repository:

```bash
git clone https://github.com/<your-username>/MNIST-ML-Models.git
cd MNIST-ML-Models
```

### Run the main script:

```bash
python ml_project11.py
```

The script will:

  * ğŸ“¥ Load and preprocess the MNIST data.
  * ğŸ¤– Train the Logistic Regression model and print its accuracy.
  * ğŸ¤– Train the SVM model (subset) and print its accuracy.
  * ğŸ–¼ï¸ Display a confusion matrix for Logistic Regression.
  * ğŸ–¼ï¸ Visualize 5 test images with predicted vs. true labels.

-----

## ğŸ“Š Results Summary

| Model | Training Subset Size | Test Set Accuracy |
| :--- | :--- | :--- |
| **Logistic Regression** | 56,000 | \~92.2% |
| **Support Vector Machine (RBF)** | 10,000 | \~96.6% |

ğŸ’¡ SVM achieves higher accuracy (approximately 96.6%) even with significantly fewer samples than the Logistic Regression model (approximately 92.2%), demonstrating the power of non-linear RBF-kernel SVM for image classification tasks.

-----

## ğŸ–¼ï¸ Visualizations

The script generates plots to assess model performance visually.

### Confusion Matrix (Logistic Regression)

A heatmap showing correct predictions along the diagonal and highlighting misclassifications off-diagonal.

### Sample Predictions

Displays the first 5 test images with the model's predicted label versus the true label for visual inspection of the model's performance.

-----

## ğŸ“œ License

This project is licensed under the **MIT License**.

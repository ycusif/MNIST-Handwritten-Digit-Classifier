üöÄ MNIST Handwritten Digit ClassificationThis project implements and compares two popular machine learning algorithms‚ÄîLogistic Regression and Support Vector Machine (SVM)‚Äîfor classifying handwritten digits from the widely-used MNIST dataset.The MNIST dataset consists of 70,000 images of handwritten digits (0-9), with each image being $28 \times 28$ pixels.üìã Project StructureThe core logic is contained within the Python script ml_project11.py.Data Source: The project uses the fetch_openml function to load the 'mnist_784' dataset.Preprocessing: The pixel values are scaled to the range $[0, 1]$ and then, for the SVM model, standardized using StandardScaler.Model Implementation:Logistic Regression: Trained on the full training set.Support Vector Machine (SVM): Trained on a smaller subset of 10,000 samples for efficiency, using an RBF kernel.Evaluation: Model performance is primarily evaluated using Accuracy Score and visualized with a Confusion Matrix.üõ†Ô∏è RequirementsTo run this project, you will need to install the following Python libraries:Bashpip install pandas numpy scikit-learn matplotlib seaborn
üèÉ Getting StartedClone the repository:Bashgit clone [https://colab.research.google.com/drive/1idaPFa1CopQbbNqhoZ8aLA7nJH33Xl0M?usp=sharing]
cd [MNIST Handwritten Digit Classifier]
Run the Python script:Bashpython ml_project11.py
The script will:Load and preprocess the MNIST data.Split the data into training (80%) and testing (20%) sets.Train the Logistic Regression model and print its accuracy.Train the SVM model (on a subset) and print its accuracy.Display a confusion matrix for the Logistic Regression predictions.Display visualizations of 5 test images along with their predicted and true labels.üìä Results SummaryThe script provides the accuracy for both models. Based on the provided code, you should see output similar to the following (actual values may vary slightly based on environment/library updates):ModelTraining Subset SizeTest Set AccuracyLogistic Regression56,000~ 92.2%Support Vector Machine (RBF)10,000~ 96.6%Note: The SVM's superior performance, even with a smaller training subset, highlights the power of non-linear models like RBF-kernel SVM for image classification tasks.üñºÔ∏è Visualizations from the ScriptThe script generates two types of visualizations:1. Confusion Matrix (Logistic Regression Example)This heatmap shows how often the classifier correctly predicts a digit (diagonal) and which digits it confuses with others (off-diagonal).2. Sample PredictionsThe script iterates through the first 5 test samples to visually compare the prediction (Pred) with the ground truth (True)
